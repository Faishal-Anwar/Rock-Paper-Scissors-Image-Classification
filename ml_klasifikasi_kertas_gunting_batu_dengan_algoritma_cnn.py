# -*- coding: utf-8 -*-
"""ML_KLASIFIKASI_KERTAS_GUNTING_BATU_DENGAN_ALGORITMA_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d0FlgH1C7dAId--H7uElGS7JmmPcqbRc

# **Rock Paper Scissors Image Classification**


---

## **Presented by**
Faishal Anwar Hasyim

[LinkedIn](https://www.linkedin.com/in/faishal-anwar-hasyim-1391682a5/) | [Instagram](https://www.instagram.com/faishalah97?igsh=azA0dGFjM3lkd2Jm) | [Dicoding Profile](https://www.dicoding.com/users/anwarfaishal86/academies)

## **Objektif**
Project ini bertujuan untuk membuat model klasifikasi gambar untuk mengklasifikasi gestur tangan batu, gunting, dan kertas.

# 1. Import Libraries
"""

# import library yang dibutuhkan
import numpy as np
import tensorflow as tf
import matplotlib as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import RMSprop

"""# 2. Prepare the dataset"""

# download file
!wget --no-check-certificate \
https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
-O rockpaperscissors.zip

# ekstrak file
import zipfile, os
local_zip = '/content/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content/dataset/rockpaperscissors')
zip_ref.close()

os.listdir('/content/dataset/rockpaperscissors/rockpaperscissors')

# path ke direktori yang akan digunakan
base_dir = '/content/dataset/rockpaperscissors/rockpaperscissors/rps-cv-images'

# direktori paper image
paper = '/content/dataset/rockpaperscissors/rockpaperscissors/paper'

# direktori rock image
rock = '/content/dataset/rockpaperscissors/rockpaperscissors/rock'

# direktori scissor image
scissors = '/content/dataset/rockpaperscissors/rockpaperscissors/scissors'

# mengecek jumlah image untuk training pada masing masing label
train_paper = os.listdir(paper)
train_rock = os.listdir(rock)
train_scissors = os.listdir(scissors)

print("Paper images:", len(train_paper))
print("Rock images:", len(train_rock))
print("Scissors images:", len(train_scissors))

"""# 3. Data preprocessing"""

# membuat Images Augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    horizontal_flip=True,
    shear_range=0.2,
    zoom_range=0.2,
    fill_mode='nearest',
    validation_split=0.4 # membagi validation set sebesar 40%
)

test_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split = 0.4
)

# membuat data generator untuk training dan validasi data
train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(150,150),
    batch_size=8,
    shuffle=True,
    class_mode='categorical',
    subset='training'
)

validation_generator = test_datagen.flow_from_directory(
    base_dir,
    target_size=(150,150),
    batch_size=8,
    shuffle=True,
    class_mode='categorical',
    subset='validation'
)

# mengecek class dan labelnya
print("classes: ", train_generator.class_indices)

"""# 4. Modeling"""

# membuat model sequential
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(512, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Dropout(0.25),
    Flatten(),
    Dense(512, activation='relu'),
    Dense(3, activation='softmax')
])

# mengecek ringkasan model
model.summary()

# membuat callback
# callback untuk menghentikan training jika akurasi di atas 96,6%
class stopTraining(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if (logs.get('accuracy') >= 0.966):
      print('Akurasi di atas 96,6%, stop training')
      self.model.stop_training = True

stop_train = stopTraining()

# callback untuk menghitung waktu pelatihan model
import time

class TimeHistory(tf.keras.callbacks.Callback):
  def on_train_begin(self, logs={}):
    self.times = []

  def on_epoch_begin(self, epoch, logs={}):
    self.epoch_time_start = time.time()

  def on_epoch_end(self, epoch, logs={}):
    self.times.append(time.time() - self.epoch_time_start)

time_callback = TimeHistory()

# compile model
model.compile(loss='categorical_crossentropy',
             optimizer='SGD',
             metrics=['accuracy'])

# melatih model
history_train = model.fit(train_generator,
                          validation_data=validation_generator,
                          steps_per_epoch=25,
                          epochs=100,
                          validation_steps=5,
                          verbose=2,
                          callbacks=[stop_train,time_callback])

"""# 5. Evaluation"""

# simpan model
from tensorflow.keras.models import Model
from tensorflow.keras.models import load_model

model.save('rock_paper_scissors_model_a1.keras')
print('Model Saved!')

# menghitung total waktu pelatihan
total_waktu = sum(time_callback.times)/60
print(f'Total waktu untuk melatih model: {total_waktu:.2f} menit')

import matplotlib.pyplot as plt

# Ambil data dari history
acc = history_train.history['accuracy']
val_acc = history_train.history['val_accuracy']

loss = history_train.history['loss']
val_loss = history_train.history['val_loss']

epochs_range = range(len(acc))  # Jumlah epoch = panjang history

# Plot Akurasi
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

plt.tight_layout()
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# melakukan prediksi dengan model
import numpy as np
from google.colab import files
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)
  outclass = np.argmax(classes)

  print(fn)
  if outclass==0:
    print('Kertas')
  elif outclass==1:
    print('Batu')
  else:
    print('Gunting')

# prediksi berikutnya
uploaded = files.upload()

for fn in uploaded.keys():
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)
  outclass = np.argmax(classes)

  print(fn)
  if outclass==0:
    print('Kertas')
  elif outclass==1:
    print('Batu')
  else:
    print('Gunting')

# prediksi berikutnya
uploaded = files.upload()

for fn in uploaded.keys():
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)
  outclass = np.argmax(classes)

  print(fn)
  if outclass==0:
    print('Kertas')
  elif outclass==1:
    print('Batu')
  else:
    print('Gunting')

!pip freeze > requirements.txt